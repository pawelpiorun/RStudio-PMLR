source("Scripts\\parametersReduction.R", echo = TRUE)
install.packages("caret")
source("Scripts\\parametersReduction.R", echo = TRUE)
#Up sample the data (this will add two more Divorced observations)
data <- caret::upSample(x = data[,-55], y = data$Class)
# Read data with first row as headers row
data <- read.table("divorce.csv", sep = ';', header = T)
summary(data$Class)
# Show heatmap of correlations
# The darker the square, the more correlated it is.
heatmap(cor(data[,-55]), Rowv=NA, Colv=NA)
# Check PCA with normalized data
pca1 <- prcomp(data[,-55], center = TRUE, scale. = TRUE)
# Use RFE method to check how can we reduce parameters number
set.seed(1)
plot(results2, type=c("g", "o"))
plot(results, type=c("g", "o"))
# Use RFE method to check how can we reduce parameters number
set.seed(1)
results <- caret::rfe(data$Class ~ ., data, sizes=c(3,5,7,9,13,20,30,40,50),
rfeControl=caret::rfeControl(functions=caret::rfFuncs,
method="cv", number=10, verbose=FALSE));
# Read data with first row as headers row
data <- read.table("divorce.csv", sep = ';', header = T)
# Read data with first row as headers row
data <- read.table("divorce.csv", sep = ';', header = T)
# Show column names
colnames(data)
#Show data
head(data)
# Prepare output
data$Class <- as.factor(data$Class)
levels(data$Class) <- c("Not divorced", "Divorced")
# Show data
head(data)
summary(data$Class)
#Up sample the data (this will add two more Divorced observations)
data <- caret::upSample(x = data[,-55], y = data$Class)
summary(data$Class)
#Add box plots in packages of 2x3, so 9 times 6 = 54 attributes
for (i in 1:9)
{
# Prepare plot space
par(mfrow=c(2,3))
for (j in 1:6)
{
# Show plot
k = (i-1)*6+j
boxplot(data[[k]] ~ Class, data = data, main=names(data)[k])
}
}; rm(i); rm(j); rm(k)
# Show heatmap of correlations
# The darker the square, the more correlated it is.
heatmap(cor(data[,-55]), Rowv=NA, Colv=NA)
# Check PCA with normalized data
pca1 <- prcomp(data[,-55], center = TRUE, scale. = TRUE)
summary(pca1)
# Check PCA without normalizing
pca2 <- prcomp(data[,-55], center = FALSE, scale. = FALSE)
summary(pca2)
# Use RFE method to check how can we reduce parameters number
set.seed(1)
results <- caret::rfe(data$Class ~ ., data, sizes=c(3,5,7,9,13,20,30,40,50),
rfeControl=caret::rfeControl(functions=caret::rfFuncs,
method="cv", number=10, verbose=FALSE));
install.packages("e1071")
# Use RFE method to check how can we reduce parameters number
set.seed(1)
results <- caret::rfe(data$Class ~ ., data, sizes=c(3,5,7,9,13,20,30,40,50),
rfeControl=caret::rfeControl(functions=caret::rfFuncs,
method="cv", number=10, verbose=FALSE));
install.packages("randomForest")
# Use RFE method to check how can we reduce parameters number
set.seed(1)
results <- caret::rfe(data$Class ~ ., data, sizes=c(3,5,7,9,13,20,30,40,50),
rfeControl=caret::rfeControl(functions=caret::rfFuncs,
method="cv", number=10, verbose=FALSE));
print(results)
plot(results, type=c("g", "o"))
# Use RFE with different function
results2 <- caret::rfe(data$Class ~ ., data, sizes=c(3,5,7,9,13,20,30,40,50),
rfeControl=caret::rfeControl(functions=caret::nbFuncs,
method="cv", number=10, verbose=FALSE));
print(results2)
install.packages("klaR")
# Use RFE with different function
results2 <- caret::rfe(data$Class ~ ., data, sizes=c(3,5,7,9,13,20,30,40,50),
rfeControl=caret::rfeControl(functions=caret::nbFuncs,
method="cv", number=10, verbose=FALSE));
print(results2)
plot(results2, type=c("g", "o"))
train_control <- trainControl(method = "cv", number = 10)
grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE))
View(train_control)
# train the model
model <- train(Species~., data=iris, trControl=train_control, method="nb", tuneGrid=grid)
#define training control cross-validation
set.seed(1)
train_control <- trainControl(method = "cv", number = 10)
train1 <- data[train_control, ]
#define training control cross-validation
set.seed(1)
model<- train(INDICESS$biomass ~ ., INDICESS, method = "lm",trControl = trainControl(method = "cv", number = 10, verboseIter = TRUE))
#define training control cross-validation
set.seed(1)
train_control <- trainControl(method = "cv", number = 10)
# fix the parameters of the algorithm
grid <- expand.grid(.fL=c(0), .usekernel=c(FALSE))
# train the model
model <- train(Species~., data=iris, trControl=train_control, method="nb", tuneGrid=grid)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
# train the model
model <- train(Fertility ~., data, method = "lm",
trControl = train.control)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
# train the model
model <- train(Diagnosis~., data, method = "lm",
trControl = train.control)
# train the model
model <- caret::train(Diagnosis~., data, method = "lm",
trControl = train.control)
View(data)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
# train the model
model <- train(data, method = "lm",
trControl = train.control)
# train the model
model <- train(Class~., data, method = "lm",
trControl = train.control)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
# train the model
model <- train(Class~., data, method = "cforest",
trControl = train.control)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
# train the model
model <- train(Class~., data, method = "cforest",
trControl = train.control)
#summerize model
print(model)
source('C:/Users/Ewa/Documents/MGR/PMLR/RStudio-PMLR-master/Scripts/crfoss-validation.R')
#define training control cross-validation
set.seed(123)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- lapply(c( 'ada', 'bag', 'bagEarth', 'bagFDA', 'blackboost, cforest, ctree'),
function (meth) {
train(Class~., data, method = meth,
trControl = train.control) })
model <- lapply(c( 'ada', 'bag', 'bagEarth', 'bagFDA', 'blackboost, cforest, ctree'),
function (meth) {
train(Class~., data, method = meth,
trControl = train.control) })
#summerize model
print(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "ada",
trControl = train.control)
#summerize model
print(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "bag",
trControl = train.control)
#summerize model
print(model)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "blackboost",
trControl = train.control)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "blackboost",
trControl = train.control)
#summerize model
print(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "blackboost",
trControl = train.control)
#summerize model
print(model)
#summerize model
print(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "cforest",
trControl = train.control)
#summerize model
print(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "ctree",
trControl = train.control)
#summerize model
print(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "xgbTree",
trControl = train.control)
model <- train(Class~., data, method = "xgbTree",
trControl = train.control)
#summerize model
print(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "xgbTree",
trControl = train.control)
#summerize model
print(model)
View(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- train(Class~., data, method = "rf",
trControl = train.control)
#summerize model
print(model)
View(model)
View(model)
source('C:/Users/Ewa/Documents/MGR/PMLR/RStudio-PMLR-master/Scripts/crfoss-validation.R')
# Peforming all scripts
source("Scripts\\loadingData.R", echo = TRUE)
source("Scripts\\balancingData.R", echo = TRUE)
source("Scripts\\visualAnalysis.R", echo = TRUE)
source("Scripts\\pcaAnalysis.R", echo = TRUE)
source("Scripts\\parametersReduction.R", echo = TRUE)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- caret::train(Class~., data, method = "rf",
trControl = train.control)
#summerize model
print(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- caret::train(Class~., data, method = "rf",
trControl = train.control)
#summerize model
print(model)
prediction <- model$pred
confusionMatrix(prediction, data$Class)
View(model)
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- caret::train(Class~., data, method = "rf",
trControl = train.control)
#summerize model
print(model)
confusionMatrix(model$pred, data$Class)
model <- caret::train(Class~., data, method = "rf",
trControl = train.control)
#summerize model
print(model)
confusionMatrix(data, model$results)
train.control <- trainControl(method = "cv", number = 10)
model <- caret::train(Class~., data, method = "rf",
trControl = train.control)
#summerize model
print(model)
pred1=model$pred()
#define training control cross-validation
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- caret::train(Class~., data, method = "rf",
trControl = train.control)
#summerize model
print(model)
pred1=model$pred
set.seed(123)
train.control <- trainControl(method = "cv", number = 10)
model <- caret::train(Class~., data, method = "rf",
trControl = train.control)
prediction <- model$pred
res <- model$results
View(model)
View(model)
set.seed(123)
ind1 = createDataPartition(data$Class, p=0.7, list=FALSE)
train1 <- data[ind1,]
test1 <- data[-ind1,]
model <- caret::train(Class~., train, method = "rf",
trControl = train.control)
model <- caret::train(Class~., train, method = "rf",
data=train1)
set.seed(123)
ind1 = createDataPartition(data$Class, p=0.7, list=FALSE)
train1 <- data[ind1,]
test1 <- data[-ind1,]
model <- caret::train(Class~., train, method = "rf",
data=train1)
set.seed(123)
ind1 = createDataPartition(data$Class, p=0.7, list=FALSE)
train1 <- data[ind1,]
test1 <- data[-ind1,]
model <- caret::train(Class~., method = "rf",
data=train1)
pred1 <- predict(model, test1)
confusionMatrix(pred1,test1$Class)
set.seed(123)
train_cont <- trainControl("LOOCV")
model2 <- train(Class~., data=data, method='lm', trControl = train_cont)
set.seed(123)
train_cont <- trainControl("LOOCV")
model2 <- train(Class~., data=data, method='rf', trControl = train_cont)
View(model)
View(model)
View(model)
View(model2)
View(model2)
set.seed(123)
train_cont <- trainControl("LOOCV")
model2 <- train(Class~., data=data, method='rf', trControl = train_cont)
pred <- model2$pred
confusionMatrix(pred, data$Class)
set.seed(123)
train_cont <- trainControl("LOOCV")
model2 <- train(Class~., data=data, method='rf', trControl = train_cont)
pred <- model2$pred
confusionMatrix(pred, train_cont$Class)
set.seed(123)
train_cont <- trainControl("LOOCV")
model2 <- train(Class~., data=data, method="r", trControl = train_cont)
set.seed(123)
train_cont <- trainControl("LOOCV")
model2 <- train(Class~., data=data, method="rf", trControl = train_cont)
pred <- model2$pred
test = data$Class
confusionMatrix(pred, data$Class)
set.seed(123)
train_cont <- trainControl(method = "cv", number =10)
model2 <- train(Class~., data=data, method="rf", trControl = train_cont)
pred <- model2$pred
View(model2)
View(model2)
set.seed(123)
train_cont <- trainControl(method = "cv", number=5)
model2 <- train(Class~., data=data, method="rf", trControl = train_cont)
pred <- model2$pred
set.seed(123)
train_cont <- trainControl(method = "LOOCV")
model2 <- train(Class~., data=data, method="rf", trControl = train_cont)
View(model2)
View(model2)
pred <- model2$pred$pred
test = data$Class
confusionMatrix(pred, data$Class)
set.seed(123)
train_cont <- trainControl(method = "LOOCV")
model2 <- train(Class~., data=data, method="rf", trControl = train_cont)
pred <- model2$pred$pred
test = model$trainingData$Class
confusionMatrix(pred, test)
set.seed(123)
train_cont <- trainControl(method = "LOOCV")
model2 <- train(Class~., data=data, method="rf", trControl = train_cont)
pred <- model2$pred$pred
test = model2$trainingData$Class
confusionMatrix(pred, test)
set.seed(123)
train_cont <- trainControl(method = "LOOCV")
model2 <- train(Class~., data=data, method="rf", trControl = train_cont)
pred <- model2$pred$pred
test = model2$pred$obs
confusionMatrix(pred, test)
source('C:/Users/Ewa/Documents/MGR/PMLR/RStudio-PMLR-master/Scripts/crfoss-validation.R')
library(caret)
# Peforming all scripts
source("Scripts\\loadingData.R", echo = TRUE)
source("Scripts\\balancingData.R", echo = TRUE)
source("Scripts\\visualAnalysis.R", echo = TRUE)
source("Scripts\\pcaAnalysis.R", echo = TRUE)
source("Scripts\\parametersReduction.R", echo = TRUE)
source("Scripts\\parametersReduction.R", echo = TRUE)
source("Scripts\\modelling.R", echo = TRUE)
library(caret)
library(caret)
library(ggplot2)
library(lattice)
# Peforming all scripts
source("Scripts\\loadingData.R", echo = TRUE)
source("Scripts\\balancingData.R", echo = TRUE)
source("Scripts\\visualAnalysis.R", echo = TRUE)
source("Scripts\\pcaAnalysis.R", echo = TRUE)
source("Scripts\\parametersReduction.R", echo = TRUE)
set.seed(123)
#Split data
ind1 = createDataPartition(data$Class, p=0.7, list=FALSE)
train1 <- data[ind1,]
test1 <- data[-ind1,]
#data modelling
model1 <- lapply(c( 'cforest', 'ctree', 'xgbTree', 'rf'),
function (met) {
caret::train(Class~., method = rf,
data=train1) })
#data modelling
model1 <- lapply(c( 'cforest', 'ctree', 'xgbTree', 'rf'),
function (met) {
caret::train(Class~., method = met,
data=train1) })
#leave one out cross validation
train_cont <- trainControl(method = "LOOCV")
#data modelling
model2 <- lapply(c( 'cforest', 'ctree', 'xgbTree', 'rf'),
function (met) {
caret::train(Class~., data=data, method=met,
trControl = train_cont) })
library(caret)
library(ggplot2)
library(lattice)
# Peforming all scripts
source("Scripts\\loadingData.R", echo = TRUE)
source("Scripts\\balancingData.R", echo = TRUE)
source("Scripts\\visualAnalysis.R", echo = TRUE)
source("Scripts\\pcaAnalysis.R", echo = TRUE)
# Use RFE method to check how can we reduce parameters number
set.seed(1)
results <- caret::rfe(data$Class ~ ., data, sizes=c(3,5,7,9,13,20,30,40,50),
rfeControl=caret::rfeControl(functions=caret::rfFuncs,
method="LOOCV", verbose=FALSE));
print(results)
plot(results, type=c("g", "o"))
# Use RFE with different function
results2 <- caret::rfe(data$Class ~ ., data, sizes=c(3,5,7,9,13,20,30,40,50),
rfeControl=caret::rfeControl(functions=caret::nbFuncs,
method="LOOCV", verbose=FALSE));
print(results2)
plot(results2, type=c("g", "o"))
set.seed(123)
#Split data
ind1 = createDataPartition(data$Class, p=0.7, list=FALSE)
train1 <- data[ind1,]
test1 <- data[-ind1,]
#data modelling
model1 <- lapply(c( 'cforest', 'ctree', 'xgbTree', 'rf'),
function (met) {
caret::train(Class~., method = met,
data=train1) })
#leave one out cross validation
train_cont <- trainControl(method = "LOOCV")
#data modelling
model2 <- lapply(c( 'cforest', 'ctree', 'xgbTree', 'rf'),
function (met) {
caret::train(Class~., data=data, method=met,
trControl = train_cont) })
#data modelling
model2 <- lapply(c( 'cforest', 'ctree', 'xgbTree', 'rf'),
function (met) {
caret::train(Class~., data=data, method=met,
trControl = train_cont) })
model2 <- lapply(c( 'cforest', 'ctree', 'xgbTree', 'rf'),
function (met) {
caret::train(Class~., data=data, method=met,
trControl = train_cont) })
set.seed((123))
pred1_cf <- predict(model1[[1]], test1)
confusionMatrix(pred1_cf,test1$Class)
set.seed((123))
pred1_cf <- predict(model1[[1]], test1)
confusionMatrix(pred1_cf,test1$Class)
pred1_ct <- predict(model1[[2]], test1)
confusionMatrix(pred1_cf,test1$Class)
pred1_xgb <- predict(model1[[3]], test1)
confusionMatrix(pred1_cf,test1$Class)
pred1_rf <- predict(model1[[4]], test1)
confusionMatrix(pred1_cf,test1$Class)
pred2_cf <- model2[[1]]$pred$pred
test2_cf = model2[[1]]$pred$obs
confusionMatrix(pred2_cf, test2_cf)
pred2_ct <- model2[[2]]$pred$pred
test2_ct <-model2[[2]]$pred$obs
confusionMatrix(pred2_ct, test2_ct)
pred2_xgb <- model2[[3]]$pred$pred
test2_xgb <- model2[[3]]$pred$obs
confusionMatrix(pred2_xgb, test2_xgb)
pred2_rf <- model2[[4]]$pred$pred
test2_rf <- model2[[4]]$pred$obs
confusionMatrix(pred2_rf, test2_rf)
